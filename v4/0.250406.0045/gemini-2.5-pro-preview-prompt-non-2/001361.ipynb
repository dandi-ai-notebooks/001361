{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa56bb84",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 001361: A flexible hippocampal population code for experience relative to reward\n",
    "\n",
    "**Disclaimer:** This notebook was AI-generated and has not been fully verified. Please be cautious when interpreting the code or results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f43a30",
   "metadata": {},
   "source": [
    "## Overview of the Dandiset\n",
    "\n",
    "This notebook explores Dandiset [001361](https://dandiarchive.org/dandiset/001361/0.250406.0045), version 0.250406.0045.\n",
    "\n",
    "**Dandiset Name:** A flexible hippocampal population code for experience relative to reward\n",
    "\n",
    "**Description:** 2-photon imaging and behavioral data from hippocampal area CA1 during virtual reality navigation in mice. Included in Sosa, Plitt, &amp; Giocomo, \"A flexible hippocampal population code for experience relative to reward,\" Nature Neuroscience.\n",
    "\n",
    "To reinforce rewarding behaviors, events leading up to and following rewards must be remembered. Hippocampal place cell activity spans spatial and non-spatial episodes, but whether hippocampal activity encodes entire sequences of events relative to reward is unknown. To test this, we performed two-photon imaging of hippocampal CA1 as mice navigated virtual environments with changing hidden reward locations. When the reward moved, a subpopulation of neurons updated their firing fields to the same relative position with respect to reward, constructing behavioral timescale sequences spanning the entire task. Over learning, this reward-relative representation became more robust as additional neurons were recruited, and changes in reward-relative firing often preceded behavioral adaptations following reward relocation. Concurrently, the spatial environment code was maintained through a parallel, dynamic subpopulation rather than through dedicated cell classes. These findings reveal how hippocampal ensembles flexibly encode multiple aspects of experience while amplifying behaviorally relevant information.\n",
    "\n",
    "This notebook will cover:\n",
    "- How to load the Dandiset using the DANDI API.\n",
    "- How to load a specific NWB file from the Dandiset.\n",
    "- How to access and summarize metadata from the NWB file.\n",
    "- How to load and visualize some of the data contained within the NWB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082ffe6",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following Python packages are required to run this notebook. It is assumed that they are already installed on your system.\n",
    "- `dandi`\n",
    "- `pynwb`\n",
    "- `h5py`\n",
    "- `remfile`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `seaborn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608491d",
   "metadata": {},
   "source": [
    "## Loading the Dandiset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6288f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:15.910823Z",
     "iopub.status.busy": "2025-05-09T16:29:15.910521Z",
     "iopub.status.idle": "2025-05-09T16:29:15.917849Z",
     "shell.execute_reply": "2025-05-09T16:29:15.916871Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1219811503.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    import numpy asnp\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import pynwb\n",
    "import h5py\n",
    "import remfile\n",
    "import numpy asnp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Connect to DANDI archive\n",
    "client = DandiAPIClient()\n",
    "dandiset_id = \"001361\"\n",
    "dandiset_version = \"0.250406.0045\"\n",
    "dandiset = client.get_dandiset(dandiset_id, dandiset_version)\n",
    "\n",
    "# Print basic information about the Dandiset\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata['name']}\")\n",
    "print(f\"Dandiset URL: {metadata['url']}\")\n",
    "\n",
    "# List some assets in the Dandiset\n",
    "assets = dandiset.get_assets()\n",
    "print(\"\\nFirst 5 assets:\")\n",
    "for asset in islice(assets, 5):\n",
    "    print(f\"- {asset.path} (ID: {asset.identifier})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476417c",
   "metadata": {},
   "source": [
    "## Loading an NWB File\n",
    "\n",
    "We will now load one of the NWB files from the Dandiset to explore its contents. We will use the file `sub-m11/sub-m11_ses-03_behavior+ophys.nwb`.\n",
    "\n",
    "The URL for this asset is constructed using its asset ID: `d77ea78a-8978-461d-9d11-3c5cef860d82`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d33317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:15.920998Z",
     "iopub.status.busy": "2025-05-09T16:29:15.920516Z",
     "iopub.status.idle": "2025-05-09T16:29:16.010951Z",
     "shell.execute_reply": "2025-05-09T16:29:16.010494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NWB file from: https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'remfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m nwb_file_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading NWB file from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnwb_file_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m remote_file \u001b[38;5;241m=\u001b[39m \u001b[43mremfile\u001b[49m\u001b[38;5;241m.\u001b[39mFile(nwb_file_url)\n\u001b[1;32m      7\u001b[0m h5_file \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(remote_file)\n\u001b[1;32m      8\u001b[0m io \u001b[38;5;241m=\u001b[39m pynwb\u001b[38;5;241m.\u001b[39mNWBHDF5IO(file\u001b[38;5;241m=\u001b[39mh5_file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Specify read-only mode\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remfile' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the NWB file\n",
    "# The URL is hard-coded here based on the information retrieved previously.\n",
    "nwb_file_url = \"https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/\"\n",
    "print(f\"Loading NWB file from: {nwb_file_url}\")\n",
    "\n",
    "remote_file = remfile.File(nwb_file_url)\n",
    "h5_file = h5py.File(remote_file)\n",
    "io = pynwb.NWBHDF5IO(file=h5_file, mode='r') # Specify read-only mode\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(\"\\nNWB file loaded successfully.\")\n",
    "print(f\"Identifier: {nwbfile.identifier}\")\n",
    "print(f\"Session description: {nwbfile.session_description}\")\n",
    "print(f\"Session start time: {nwbfile.session_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2badf",
   "metadata": {},
   "source": [
    "You can also explore this NWB file interactively on NeuroSift:\n",
    "[https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/&dandisetId=001361&dandisetVersion=draft](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/&dandisetId=001361&dandisetVersion=draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845b09e",
   "metadata": {},
   "source": [
    "## Summarizing NWB File Contents\n",
    "\n",
    "Let's look at the structure of the NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5735d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.012281Z",
     "iopub.status.busy": "2025-05-09T16:29:16.012178Z",
     "iopub.status.idle": "2025-05-09T16:29:16.021208Z",
     "shell.execute_reply": "2025-05-09T16:29:16.020908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key groups and datasets in the NWB file:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey groups and datasets in the NWB file:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Acquisition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39macquisition\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Processing modules: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(nwbfile\u001b[38;5;241m.\u001b[39mprocessing\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Key groups and datasets in the NWB file:\")\n",
    "print(f\"- Acquisition: {list(nwbfile.acquisition.keys())}\")\n",
    "if nwbfile.processing:\n",
    "    print(f\"- Processing modules: {list(nwbfile.processing.keys())}\")\n",
    "    if \"behavior\" in nwbfile.processing:\n",
    "        print(f\"  - Behavior data interfaces: {list(nwbfile.processing['behavior'].data_interfaces.keys())}\")\n",
    "        if \"BehavioralTimeSeries\" in nwbfile.processing[\"behavior\"].data_interfaces:\n",
    "            print(f\"    - BehavioralTimeSeries: {list(nwbfile.processing['behavior'].data_interfaces['BehavioralTimeSeries'].time_series.keys())}\")\n",
    "    if \"ophys\" in nwbfile.processing:\n",
    "        print(f\"  - Ophys data interfaces: {list(nwbfile.processing['ophys'].data_interfaces.keys())}\")\n",
    "else:\n",
    "    print(\"- No processing modules found.\")\n",
    "print(f\"- Devices: {list(nwbfile.devices.keys())}\")\n",
    "print(f\"- Imaging planes: {list(nwbfile.imaging_planes.keys())}\")\n",
    "print(f\"- Subject information: {nwbfile.subject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdd19e",
   "metadata": {},
   "source": [
    "### Behavioral Data\n",
    "\n",
    "The NWB file contains several time series related to behavior. We can list them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddd5731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.022341Z",
     "iopub.status.busy": "2025-05-09T16:29:16.022258Z",
     "iopub.status.idle": "2025-05-09T16:29:16.028974Z",
     "shell.execute_reply": "2025-05-09T16:29:16.028696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39mprocessing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces:\n\u001b[1;32m      2\u001b[0m     behavior_ts \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtime_series\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioral Time Series:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "if \"behavior\" in nwbfile.processing and \"BehavioralTimeSeries\" in nwbfile.processing[\"behavior\"].data_interfaces:\n",
    "    behavior_ts = nwbfile.processing[\"behavior\"].data_interfaces[\"BehavioralTimeSeries\"].time_series\n",
    "    print(\"Behavioral Time Series:\")\n",
    "    for ts_name, ts_data in behavior_ts.items():\n",
    "        print(f\"- {ts_name}: {ts_data.description} (shape: {ts_data.data.shape}, unit: {ts_data.unit})\")\n",
    "else:\n",
    "    print(\"BehavioralTimeSeries not found in processing['behavior'].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b63ae",
   "metadata": {},
   "source": [
    "Let's visualize the mouse's position on the virtual linear track over a short period.\n",
    "We will load the first 500 data points and corresponding timestamps for `position`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1a1be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.030054Z",
     "iopub.status.busy": "2025-05-09T16:29:16.029975Z",
     "iopub.status.idle": "2025-05-09T16:29:16.037757Z",
     "shell.execute_reply": "2025-05-09T16:29:16.037421Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mset_theme() \u001b[38;5;66;03m# Apply seaborn styling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtime_series:\n\u001b[1;32m      7\u001b[0m     position_ts \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtime_series[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_theme() # Apply seaborn styling\n",
    "\n",
    "if \"behavior\" in nwbfile.processing and \\\n",
    "   \"BehavioralTimeSeries\" in nwbfile.processing[\"behavior\"].data_interfaces and \\\n",
    "   \"position\" in nwbfile.processing[\"behavior\"].data_interfaces[\"BehavioralTimeSeries\"].time_series:\n",
    "\n",
    "    position_ts = nwbfile.processing[\"behavior\"].data_interfaces[\"BehavioralTimeSeries\"].time_series[\"position\"]\n",
    "    num_points_to_plot = 500\n",
    "\n",
    "    if len(position_ts.data) >= num_points_to_plot:\n",
    "        position_data_subset = position_ts.data[:num_points_to_plot]\n",
    "        position_timestamps_subset = position_ts.timestamps[:num_points_to_plot]\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(position_timestamps_subset, position_data_subset)\n",
    "        plt.xlabel(f\"Time ({position_ts.timestamps_unit})\")\n",
    "        plt.ylabel(f\"Position ({position_ts.unit})\")\n",
    "        plt.title(f\"Mouse Position (First {num_points_to_plot} points)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Not enough data points in 'position' to plot {num_points_to_plot} points. Available: {len(position_ts.data)}\")\n",
    "else:\n",
    "    print(\"'position' time series not found in behavioral data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee6893",
   "metadata": {},
   "source": [
    "Let's also look at the lick data for the same time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d5c847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.038982Z",
     "iopub.status.busy": "2025-05-09T16:29:16.038878Z",
     "iopub.status.idle": "2025-05-09T16:29:16.047889Z",
     "shell.execute_reply": "2025-05-09T16:29:16.047500Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39mprocessing \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      2\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      3\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlick\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtime_series:\n\u001b[1;32m      5\u001b[0m     lick_ts \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavioralTimeSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtime_series[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlick\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# We use the same number of points as for position for easier comparison, if available\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "if \"behavior\" in nwbfile.processing and \\\n",
    "   \"BehavioralTimeSeries\" in nwbfile.processing[\"behavior\"].data_interfaces and \\\n",
    "   \"lick\" in nwbfile.processing[\"behavior\"].data_interfaces[\"BehavioralTimeSeries\"].time_series:\n",
    "\n",
    "    lick_ts = nwbfile.processing[\"behavior\"].data_interfaces[\"BehavioralTimeSeries\"].time_series[\"lick\"]\n",
    "    # We use the same number of points as for position for easier comparison, if available\n",
    "    num_points_to_plot = 500\n",
    "\n",
    "    if len(lick_ts.data) >= num_points_to_plot:\n",
    "        lick_data_subset = lick_ts.data[:num_points_to_plot]\n",
    "        lick_timestamps_subset = lick_ts.timestamps[:num_points_to_plot] # Assuming timestamps align or are similar rate\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(lick_timestamps_subset, lick_data_subset)\n",
    "        plt.xlabel(f\"Time ({lick_ts.timestamps_unit})\")\n",
    "        plt.ylabel(f\"Lick ({lick_ts.unit})\")\n",
    "        plt.title(f\"Lick Data (First {num_points_to_plot} points)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Not enough data points in 'lick' to plot {num_points_to_plot} points. Available: {len(lick_ts.data)}\")\n",
    "else:\n",
    "    print(\"'lick' time series not found in behavioral data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15285d31",
   "metadata": {},
   "source": [
    "### Optical Physiology (Ophys) Data\n",
    "\n",
    "The NWB file also contains optical physiology data. Let's examine the available ophys data interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee486d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.049189Z",
     "iopub.status.busy": "2025-05-09T16:29:16.049091Z",
     "iopub.status.idle": "2025-05-09T16:29:16.058297Z",
     "shell.execute_reply": "2025-05-09T16:29:16.058027Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39mprocessing:\n\u001b[1;32m      2\u001b[0m     ophys_interfaces \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOphys Data Interfaces:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "if \"ophys\" in nwbfile.processing:\n",
    "    ophys_interfaces = nwbfile.processing[\"ophys\"].data_interfaces\n",
    "    print(\"Ophys Data Interfaces:\")\n",
    "    for name, interface in ophys_interfaces.items():\n",
    "        print(f\"- {name} (type: {type(interface).__name__})\")\n",
    "        if isinstance(interface, pynwb.ophys.Fluorescence):\n",
    "            print(\"  Contains ROI response series:\")\n",
    "            for rrs_name, rrs_data in interface.roi_response_series.items():\n",
    "                print(f\"    - {rrs_name}: shape {rrs_data.data.shape}, rate {rrs_data.rate} Hz\")\n",
    "        elif isinstance(interface, pynwb.ophys.ImageSegmentation):\n",
    "            print(\"  Contains plane segmentations:\")\n",
    "            for ps_name, ps_data in interface.plane_segmentations.items():\n",
    "                print(f\"    - {ps_name}: {len(ps_data.id)} ROIs\")\n",
    "        elif isinstance(interface, pynwb.base.Images):\n",
    "            print(\"  Contains images:\")\n",
    "            for img_name in interface.images.keys():\n",
    "                print(f\"    - {img_name}\")\n",
    "else:\n",
    "    print(\"Ophys processing module not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf936ed",
   "metadata": {},
   "source": [
    "#### ROI Fluorescence Traces\n",
    "\n",
    "We can plot the fluorescence traces for a few ROIs (Regions of Interest, likely individual cells).\n",
    "Let's look at the `Fluorescence` data, specifically `plane0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d28febc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.059397Z",
     "iopub.status.busy": "2025-05-09T16:29:16.059312Z",
     "iopub.status.idle": "2025-05-09T16:29:16.069279Z",
     "shell.execute_reply": "2025-05-09T16:29:16.068967Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nwbfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnwbfile\u001b[49m\u001b[38;5;241m.\u001b[39mprocessing \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      2\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluorescence\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m      3\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplane0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluorescence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mroi_response_series:\n\u001b[1;32m      5\u001b[0m     fluorescence_rrs \u001b[38;5;241m=\u001b[39m nwbfile\u001b[38;5;241m.\u001b[39mprocessing[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mophys\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata_interfaces[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluorescence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mroi_response_series[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplane0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     num_rois_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nwbfile' is not defined"
     ]
    }
   ],
   "source": [
    "if \"ophys\" in nwbfile.processing and \\\n",
    "   \"Fluorescence\" in nwbfile.processing[\"ophys\"].data_interfaces and \\\n",
    "   \"plane0\" in nwbfile.processing[\"ophys\"].data_interfaces[\"Fluorescence\"].roi_response_series:\n",
    "\n",
    "    fluorescence_rrs = nwbfile.processing[\"ophys\"].data_interfaces[\"Fluorescence\"].roi_response_series[\"plane0\"]\n",
    "    num_rois_to_plot = 3\n",
    "    num_timepoints_to_plot = 500 # Plot a subset of timepoints to keep it manageable\n",
    "\n",
    "    if fluorescence_rrs.data.shape[1] >= num_rois_to_plot and fluorescence_rrs.data.shape[0] >= num_timepoints_to_plot:\n",
    "        roi_indices_to_plot = np.arange(num_rois_to_plot) # Plot first N ROIs\n",
    "        actual_roi_ids = fluorescence_rrs.rois.table.id[:num_rois_to_plot]\n",
    "\n",
    "        fluorescence_data_subset = fluorescence_rrs.data[:num_timepoints_to_plot, roi_indices_to_plot]\n",
    "\n",
    "        # Generate timestamps for the subset\n",
    "        # Timestamps are not directly stored per data point, but can be calculated from starting_time and rate\n",
    "        time_vector = fluorescence_rrs.starting_time + np.arange(num_timepoints_to_plot) / fluorescence_rrs.rate\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i, roi_idx in enumerate(roi_indices_to_plot):\n",
    "            plt.plot(time_vector, fluorescence_data_subset[:, i], label=f\"ROI ID {actual_roi_ids[i]}\")\n",
    "\n",
    "        plt.xlabel(f\"Time ({fluorescence_rrs.starting_time_unit})\")\n",
    "        plt.ylabel(f\"Fluorescence ({fluorescence_rrs.unit})\")\n",
    "        plt.title(f\"Fluorescence Traces (First {num_rois_to_plot} ROIs, First {num_timepoints_to_plot} Timepoints)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Not enough ROIs or timepoints in Fluorescence/plane0. Available ROIs: {fluorescence_rrs.data.shape[1]}, Available Timepoints: {fluorescence_rrs.data.shape[0]}\")\n",
    "else:\n",
    "    print(\"Fluorescence/plane0 data not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91423d",
   "metadata": {},
   "source": [
    "#### Image Segmentation and ROI Masks\n",
    "\n",
    "The `ImageSegmentation` interface provides information about the ROIs, including their pixel masks.\n",
    "Let's try to visualize the spatial layout of some ROIs. We'll use the `PlaneSegmentation` within `ImageSegmentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a21447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.070492Z",
     "iopub.status.busy": "2025-05-09T16:29:16.070396Z",
     "iopub.status.idle": "2025-05-09T16:29:16.075156Z",
     "shell.execute_reply": "2025-05-09T16:29:16.074848Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (255363935.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    if 0 &lt;= y_coord &lt; img_dims[0] and 0 &lt;= x_coord &lt; img_dims[1]:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# No seaborn styling for images\n",
    "plt.style.use('default')\n",
    "\n",
    "if \"ophys\" in nwbfile.processing and \\\n",
    "   \"ImageSegmentation\" in nwbfile.processing[\"ophys\"].data_interfaces and \\\n",
    "   \"PlaneSegmentation\" in nwbfile.processing[\"ophys\"].data_interfaces[\"ImageSegmentation\"].plane_segmentations:\n",
    "\n",
    "    plane_segmentation = nwbfile.processing[\"ophys\"].data_interfaces[\"ImageSegmentation\"].plane_segmentations[\"PlaneSegmentation\"]\n",
    "\n",
    "    # Get image dimensions from the imaging plane associated with the TwoPhotonSeries\n",
    "    # This assumes there's a TwoPhotonSeries associated with this plane.\n",
    "    # A more robust way would be to check plane_segmentation.imaging_plane or reference_images if available.\n",
    "    # For this example, we'll try to get it from the TwoPhotonSeries if it exists, otherwise assume default.\n",
    "    img_dims = None\n",
    "    if \"TwoPhotonSeries\" in nwbfile.acquisition:\n",
    "        ts_img = nwbfile.acquisition[\"TwoPhotonSeries\"]\n",
    "        if ts_img.dimension is not None and len(ts_img.dimension) >= 2:\n",
    "             # Dimension usually is [height, width] or [depth, height, width]\n",
    "             # For 2D imaging, it's [height, width]\n",
    "            img_dims = ts_img.dimension[:2] # Assuming 2D for simplicity, might be [y,x]\n",
    "            img_dims = [int(d) for d in img_dims] # Ensure they are integers\n",
    "            print(f\"Image dimensions from TwoPhotonSeries: {img_dims}\")\n",
    "\n",
    "\n",
    "    # Fallback or if we need to use reference images dimensions\n",
    "    if img_dims is None and plane_segmentation.reference_images:\n",
    "        # This part is more complex as reference_images might not directly give dimensions\n",
    "        # or might be a list of images. For simplicity, we'll skip this for now.\n",
    "        print(\"Could not robustly determine image dimensions from TwoPhotonSeries, and reference_images parsing is complex.\")\n",
    "\n",
    "    if img_dims is None:\n",
    "        # If we still don't have dimensions, we might need to infer from pixel masks or a reference image.\n",
    "        # Let's try to get it from a reference image if available (e.g. meanImg)\n",
    "        if \"ophys\" in nwbfile.processing and \"Backgrounds_0\" in nwbfile.processing[\"ophys\"].data_interfaces:\n",
    "            backgrounds = nwbfile.processing[\"ophys\"].data_interfaces[\"Backgrounds_0\"]\n",
    "            if \"meanImg\" in backgrounds.images:\n",
    "                mean_image = backgrounds.images[\"meanImg\"].data\n",
    "                if mean_image is not None and hasattr(mean_image, 'shape'):\n",
    "                    img_dims = mean_image.shape\n",
    "                    print(f\"Image dimensions from meanImg: {img_dims}\")\n",
    "\n",
    "\n",
    "    if img_dims:\n",
    "        num_rois_to_show = min(10, len(plane_segmentation.id)) # Show up to 10 ROIs\n",
    "        all_masks_image = np.zeros(img_dims, dtype=float)\n",
    "\n",
    "        print(f\"Attempting to plot masks for the first {num_rois_to_show} ROIs.\")\n",
    "        for i in range(num_rois_to_show):\n",
    "            try:\n",
    "                # pixel_mask is a list of (y, x, weight) tuples for each ROI\n",
    "                pixel_mask_data = plane_segmentation[\"pixel_mask\"][i]\n",
    "                for y_coord, x_coord, weight in pixel_mask_data:\n",
    "                    if 0 &lt;= y_coord &lt; img_dims[0] and 0 &lt;= x_coord &lt; img_dims[1]:\n",
    "                         # Some masks might have weights > 1 due to Suite2p format, clip or normalize if necessary\n",
    "                        all_masks_image[int(y_coord), int(x_coord)] = max(all_masks_image[int(y_coord), int(x_coord)], weight)\n",
    "            except IndexError:\n",
    "                print(f\"Warning: Could not access pixel_mask for ROI index {i}. Skipping.\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing pixel_mask for ROI index {i}: {e}. Skipping.\")\n",
    "                continue\n",
    "        \n",
    "        if np.any(all_masks_image > 0): # Check if any masks were actually added\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            # Use np.max for overlaying, assuming weights are somewhat like probabilities or intensities\n",
    "            # The previous loop already effectively did a max accumulation per pixel.\n",
    "            plt.imshow(all_masks_image, cmap='viridis', aspect='auto', origin='lower')\n",
    "            plt.title(f\"Overlay of First {num_rois_to_show} ROI Masks\")\n",
    "            plt.xlabel(\"X pixel\")\n",
    "            plt.ylabel(\"Y pixel\")\n",
    "            plt.colorbar(label=\"Max Mask Weight\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No ROI masks could be plotted. The combined mask image is empty.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Could not determine image dimensions to plot ROI masks.\")\n",
    "        print(\"To visualize ROI masks, image dimensions are needed. These can often be found in:\")\n",
    "        print(\"- `nwbfile.acquisition['TwoPhotonSeries'].dimension`\")\n",
    "        print(\"- The shape of a reference image like `nwbfile.processing['ophys'].data_interfaces['Backgrounds_0'].images['meanImg'].data`\")\n",
    "        print(\"- `plane_segmentation.imaging_plane.grid_spacing` combined with pixel counts if available.\")\n",
    "\n",
    "else:\n",
    "    print(\"ImageSegmentation/PlaneSegmentation data not found or image dimensions could not be determined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8007b3",
   "metadata": {},
   "source": [
    "## Summary and Future Directions\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "- Load a Dandiset and inspect its basic metadata and assets.\n",
    "- Load a specific NWB file from the Dandiset using its DANDI API URL.\n",
    "- Access and summarize key metadata and data structures within the NWB file, including behavioral time series and optical physiology data (fluorescence traces, ROI masks).\n",
    "- Create basic visualizations of position, lick data, and ROI fluorescence.\n",
    "- Attempt to visualize ROI masks overlayed on an image.\n",
    "\n",
    "**Potential Future Directions for Analysis:**\n",
    "- **Correlate neural activity with behavior:** Investigate how the fluorescence activity of individual neurons or populations relates to specific behavioral events (e.g., animal's position, speed, reward consumption, trial events).\n",
    "- **Analyze place cell properties:** If the data contains spatial information and neural activity from the hippocampus, one could analyze place cell characteristics (e.g., field size, stability, remapping across environments or learning).\n",
    "- **Population coding analysis:** Explore how ensembles of neurons collectively represent information about the environment, task variables, or internal states.\n",
    "- **Task-related modulation of activity:** Examine how neural activity changes across different phases of a trial or in response to specific task events (e.g., stimulus presentation, reward delivery).\n",
    "- **Cross-session comparisons:** If data from multiple sessions are available for the same subject/neurons, investigate learning-related changes in neural representations.\n",
    "\n",
    "Remember that this notebook provides a starting point. Deeper analysis would require more sophisticated techniques and careful consideration of the experimental design and data characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b51b53",
   "metadata": {},
   "source": [
    "It's important to close the HDF5 file and the remfile object if you are done with them, especially in scripts.\n",
    "However, in a Jupyter notebook context, this is often omitted for brevity as the kernel shutdown usually handles it.\n",
    "For completeness:\n",
    "```python\n",
    "# io.close()\n",
    "# h5_file.close()\n",
    "# remote_file.close()\n",
    "```\n",
    "We will leave them open for now as the notebook execution might need them if cells are re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1961d3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T16:29:16.076214Z",
     "iopub.status.busy": "2025-05-09T16:29:16.076134Z",
     "iopub.status.idle": "2025-05-09T16:29:16.078097Z",
     "shell.execute_reply": "2025-05-09T16:29:16.077799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook execution finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

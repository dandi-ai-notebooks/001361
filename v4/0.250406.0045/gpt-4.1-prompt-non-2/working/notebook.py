# %% [markdown]
# # Exploring Dandiset 001361: A flexible hippocampal population code for experience relative to reward
#
# ---
#
# **AI-generated caution:**  
# This notebook was generated by AI and has not been fully verified by a human. Please use caution when interpreting code or results—check details and logic before drawing firm conclusions or using for research!
#
# ---
#
# ## Overview
#
# **Dandiset Name:** A flexible hippocampal population code for experience relative to reward  
# **Identifier:** DANDI:001361/0.250406.0045  
# **Link to Dandiset:** [https://dandiarchive.org/dandiset/001361/0.250406.0045](https://dandiarchive.org/dandiset/001361/0.250406.0045)
#
# **Citation:**  
# Sosa, Marielena; Plitt, Mark H.; Giocomo, Lisa M. (2025) A flexible hippocampal population code for experience relative to reward (Version 0.250406.0045) [Data set]. DANDI Archive. https://doi.org/10.48324/dandi.001361/0.250406.0045
#
# **Contributors:** National Institutes of Health (NIH), Sosa, Marielena, Plitt, Mark H., Giocomo, Lisa M.
#
# **Description:**  
# 2-photon imaging and behavioral data from hippocampal area CA1 during virtual reality navigation in mice. Included in Sosa, Plitt, & Giocomo, "A flexible hippocampal population code for experience relative to reward," Nature Neuroscience.
#
# The data includes:
# - Processed and raw two-photon imaging
# - Accompanying behavioral time series (reward delivery, licking, position, trial events)
#
# **Keywords:** hippocampus, navigation, learning, memory, 2-photon imaging, place cells
#
# ---
#
# ## What will this notebook cover?
#
# - Show how to explore assets in this Dandiset
# - Load an NWB file and examine its structure
# - Summarize and visualize behavioral and imaging data
# - Provide guidance for working with this data and direct links for further exploration
# - Offer suggestions for future analyses
#
# ---
#
# ## Required packages
#
# _These Python packages are required and are assumed to already be installed:_
#
# - numpy
# - matplotlib
# - pandas
# - pynwb
# - h5py
# - remfile
# 
# _If needed, install with pip in your own environment. No installation commands are included here._
#
# ---

# %%
# List some assets in the Dandiset using the DANDI API
from itertools import islice
from dandi.dandiapi import DandiAPIClient

client = DandiAPIClient()
dandiset = client.get_dandiset("001361", "0.250406.0045")

metadata = dandiset.get_raw_metadata()
print(f"Dandiset name: {metadata['name']}")
print(f"Dandiset URL: {metadata['url']}")

# List first 5 assets
assets = dandiset.get_assets()
print("\nFirst 5 assets:")
for asset in islice(assets, 5):
    print(f"- {asset.path} (ID: {asset.identifier})")

# %% [markdown]
# ---
# 
# ## Selecting an NWB file to explore
# 
# For illustration, we will work with the following NWB file:
# 
# - **Path:** `sub-m11/sub-m11_ses-03_behavior+ophys.nwb`
# - **Asset ID:** d77ea78a-8978-461d-9d11-3c5cef860d82  
# - **Download URL:**  
#   `https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/`
# 
# You can also view this file online at Neurosift:
# [Explore NWB file on neurosift](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/&dandisetId=001361&dandisetVersion=draft)
#
# ---
# 
# ## Loading the NWB file
# The following code shows how to load the NWB file using `pynwb` and `remfile`.  
# (Data is streamed directly from DANDI's servers.)

# %%
import pynwb
import h5py
import remfile

nwb_url = "https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/"
remote_file = remfile.File(nwb_url)
h5_file = h5py.File(remote_file)
io = pynwb.NWBHDF5IO(file=h5_file)
nwb = io.read()

print("Session description:", nwb.session_description)
print("Subject ID:", nwb.subject.subject_id)
print("Session start time:", nwb.session_start_time)
print("Experimenter:", nwb.experimenter)

# %% [markdown]
# ---
# ## NWB File Structure Overview
# 
# The selected NWB file contains:
# 
# ```
# NWBFile
# ├─ session_description: processed suite2p data
# ├─ subject: m11 (Mus musculus, M)
# ├─ acquisition
# │   └─ TwoPhotonSeries: 2-photon imaging voltage (shape: (1, 1, 1), rate: 15.5 Hz)
# ├─ processing
# │   ├─ behavior (BehavioralTimeSeries)
# │   │   └─ TimeSeries: Reward, autoreward, environment, lick, position, reward_zone, scanning, speed, teleport, trial number, trial_start
# │   ├─ ophys (optical physiology, Suite2p-processed ROIs and signals)
# │   │   ├─ Backgrounds_0 (Images): Vcorr, max_proj, meanImg
# │   │   ├─ Deconvolved (Fluorescence): plane0 (19818 frames, 349 ROIs)
# │   │   ├─ Fluorescence: plane0 (19818 frames, 349 ROIs)
# │   │   ├─ Neuropil: plane0 (19818 frames, 349 ROIs)
# │   │   └─ ImageSegmentation (PlaneSegmentation, ROIs)
# ├─ imaging_planes (1): hippocampus, CA1
# └─ devices: Neurolabware microscope
# ```
# 
# **Key behavioral signals:** `position`, `lick`, `reward`, `speed`, `trial_start`, etc.  
# **Optical signals:** Processed fluorescence traces, deconvolved traces, and segmentation masks for ROIs.

# %% [markdown]
# ---
# ### Behavioral time series overview
#
# These time series are stored under:
# ```
# nwb.processing['behavior'].data_interfaces['BehavioralTimeSeries'].time_series
# ```
# The following time series are available:
#
# - Reward
# - autoreward
# - environment
# - lick
# - position
# - reward_zone
# - scanning
# - speed
# - teleport
# - trial number
# - trial_start
#
# Let's list the number of samples for each and preview some example data.

# %%
import numpy as np
ts = nwb.processing['behavior'].data_interfaces['BehavioralTimeSeries'].time_series

# For display
series_names = list(ts.keys())
sample_counts = {name: ts[name].data.shape[0] for name in series_names}

import pandas as pd
sample_tbl = pd.DataFrame({
    'Signal': list(sample_counts.keys()),
    'n_samples': list(sample_counts.values()),
    'Units': [ts[name].unit for name in series_names],
    'Description': [ts[name].description for name in series_names],
})

display(sample_tbl)

# %% [markdown]
# ---
# ### Plotting position and speed for the first lap
#
# Let's visualize the animal's movement (position and speed) for a short time interval (first 1000 samples):

# %%
import matplotlib.pyplot as plt

idx = slice(0, 1000)
time = ts['position'].timestamps[idx]
position = ts['position'].data[idx]
speed = ts['speed'].data[idx]

plt.figure(figsize=(12, 4))
plt.subplot(2,1,1)
plt.plot(time, position)
plt.ylabel('Position (cm)')
plt.title('Position during first ~1000 samples')
plt.subplot(2,1,2)
plt.plot(time, speed)
plt.ylabel('Speed (cm/s)')
plt.xlabel('Time (s)')
plt.tight_layout()
plt.show()

# %% [markdown]
# ---
# ## Ophys fluorescence & ROI exploration
#
# Suite2p-processed ROI time series are found under `nwb.processing['ophys']`.
#
# There are two types of ROI signals:
# - **Fluorescence:** Raw signals (plane0)
# - **Deconvolved:** Denoised events (plane0)
#
# Each array is (n_frames, n_rois). Let's plot traces for the first 5 ROIs:

# %%
# Load fluorescence traces and plot for 5 example ROIs
fluo = nwb.processing['ophys'].data_interfaces['Fluorescence'].roi_response_series['plane0'].data
decov = nwb.processing['ophys'].data_interfaces['Deconvolved'].roi_response_series['plane0'].data

times = np.arange(fluo.shape[0]) / ts['position'].timestamps_unit if hasattr(ts['position'], 'timestamps_unit') else np.arange(fluo.shape[0])

plt.figure(figsize=(12,5))
for i in range(5):
    plt.plot(fluo[:, i] + 2*i, label=f'ROI {i}')
plt.xlabel('Frame')
plt.ylabel('Fluorescence (a.u.) (offset for clarity)')
plt.title('Example raw fluorescence traces for 5 ROIs')
plt.legend()
plt.show()

plt.figure(figsize=(12,5))
for i in range(5):
    plt.plot(decov[:, i] + 2*i, label=f'ROI {i}')
plt.xlabel('Frame')
plt.ylabel('Deconvolved (a.u.) (offset for clarity)')
plt.title('Example deconvolved event traces for 5 ROIs')
plt.legend()
plt.show()

# %% [markdown]
# ---
# ### Exploring ROI segmentation
#
# ROI segmentation is stored in a PlaneSegmentation table:
# ```
# plane_seg = nwb.processing['ophys'].data_interfaces['Fluorescence'].roi_response_series['plane0'].rois.table
# ```
# This can be converted to a pandas DataFrame for exploration:
#
# - `pixel_mask`: pixels contributing to the ROI
# - `iscell`: whether the ROI was identified as a cell or not
# - `planeIdx`: recording plane
#
# Let's look at the first 5 ROIs:

# %%
plane_seg = nwb.processing['ophys'].data_interfaces['Fluorescence'].roi_response_series['plane0'].rois.table
df_roi = plane_seg.to_dataframe()
display(df_roi.head())

# %% [markdown]
# ---
# ### Visualizing an ROI mask (for the first ROI)
#
# The ROI pixel_mask lists pixels (row, col, weight) as a list for each ROI.
# Let's view the mask for ROI 0 as an image.

# %%
# Determine shape from imaging plane
im_shape = [int(x) for x in plane_seg.imaging_plane.grid_spacing[:]]
roi_mask = np.zeros(im_shape)
for row, col, weight in df_roi.iloc[0]['pixel_mask']:
    roi_mask[int(row), int(col)] = weight

plt.imshow(roi_mask, cmap='hot')
plt.title('Pixel mask for ROI 0')
plt.colorbar(label='Weight')
plt.axis('off')
plt.show()

# %% [markdown]
# ---
# ### Advanced visualization: Population activity heatmap
#
# Let's visualize normalized population activity (fluorescence) for the first 50 ROIs and 500 frames:

# %%
z_fluo = (fluo[:500, :50] - np.mean(fluo[:500, :50], axis=0)) / (np.std(fluo[:500, :50], axis=0) + 1e-6)
plt.figure(figsize=(10, 8))
plt.imshow(z_fluo.T, aspect='auto', cmap='viridis', interpolation='nearest')
plt.xlabel('Frame')
plt.ylabel('ROI')
plt.title('Heatmap: Normalized fluorescence (first 50 ROIs, 500 frames)')
plt.colorbar(label='Z-score')
plt.show()

# %% [markdown]
# ---
# ## Summary and future directions
#
# This notebook demonstrated how to explore the structure and basic contents of a two-photon imaging/behavioral NWB file in Dandiset 001361.  
# You have seen how to:
# - List and examine assets from the Dandiset
# - Load and inspect NWB file structure and contents using `pynwb`
# - Explore and visualize behavioral and calcium imaging time series
# - Visualize ROI segmentations and masks
#
# **Next steps and possible analyses:**
# - Explore additional behavioral correlates (licking, trial outcomes, reward location)
# - Identify place cells or analyze population code stability across reward switches
# - Correlate movement, events, and ROI fluorescence over trials or laps
# - Work with other NWB files in the Dandiset for comparison/reproducibility
#
# For further exploration, you can browse additional assets and explore files online at Neurosift ([link](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/d77ea78a-8978-461d-9d11-3c5cef860d82/download/&dandisetId=001361&dandisetVersion=draft)).
#
# Happy analyzing!